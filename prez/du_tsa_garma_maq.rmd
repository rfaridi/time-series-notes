
class: inverse, middle, center

# MA(q) process: Definition and properties 

---

## MA process


A moving average (MA) process of order $q$ is a linear combination of the current white noise term

The q most recent past white noise terms and is defined by
$$x_t=w_t+\beta_1w_{t-1}+\ldots+\beta_1w_{t-q}$$ 

Here ${w_t}$ is white noise with zero mean and variance $\sigma_w^2$. 

---


## MA equation with backshift operator

The above equation can be rewritten in terms of the backward shift operator `B`

$$x_t=(1+\beta_1B+\beta_2B^2+\ldots+\beta_qB^q)wt=\phi_q(B)w_t$$ 

Here $\phi_q$ is a polynomial of order $q$. 

MA processes consist of a finite sum stationary white noise terms 

They are stationary and hence have a time-invariant mean and autocovariance 

---

## Mean and variance of MA process

The mean and variance for ${x_t}$ are easy to derive 

The mean is just zero because it is a sum of terms that all have a mean of zero 

The variance is $\sigma{^2}_{w}(1+\beta_1^2+\ldots+\beta^2_q)$ 

Each of the white noise terms has the same variance and the terms are mutually independent. 


## Autocorrelation function and MA process 

The autocorrelation function for an $MA(q)$ process can readily be implemented in `R` 

Note that the function takes the lag $k$ and the model parameters $\beta_i$ for $i=0,1,\ldots,q,$ with $\beta_0=1$

---

## R codes

The autocorrelation function is computed in two stages using a `for` loop 

```{r }
rho <- function(k, beta) {
q <- length(beta) - 1
if (k > q) ACF <- 0 else {
s1 <- 0; s2 <- 0
for (i in 1:(q-k+1)) s1 <- s1 + beta[i] * beta[i+k]
for (i in 1:(q+1)) s2 <- s2 + beta[i]^2
ACF <- s1 / s2}
ACF}

```

The first loop generates a sum $(s1)$ for the autocovariance

The second loop generates a sum $(s2)$ for the variance with the division of the two sums giving the returned autocorrelation (ACF) 


**Using the code**

Using the code above for the autocorrelation function, correlograms for a range of $MA(q)$ processes can be plotted against lag 

The code in the next slide  provides an example for an $MA(3)$ process with parameters $\beta_1=0.7, \beta_2=0.5,$ and $\beta_3=0.2$ 

---

##  Autocovariance function


.pull-left[
The plot on the right is the autocovariance function for an $MA(3)$ process with parameters $\beta_1=-0.7, \beta_2=0.5, \beta_3=-0.2$ 

Negative correlations at lags 1 and 3 

The code below can be used to simulate the $MA(3)$ process 

Plot the correlogram of the simulated series 

An example time plot and correlogram are show in the figure 

As expected, the first three autocorrelations are significantly different from 0 

Other statistically significant correlations are attributable ro random sampling variation 

In the correlogram plot, 1 in 20 (5%) of the sample correlations for lags greater than 3 
]

.pull-right[

```{r }
beta <- c(1, 0.7, 0.5, 0.2)
rho.k <- rep(1, 10)
for (k in 1:10) rho.k[k] <- rho(k, beta)
plot(0:10, c(1, rho.k), pch = 4, ylab = expression(rho[k]))
abline(0,0)
```
]

---

Here the underlying population correlation is zero are expected to be statistically significantly different from zero at the 5% level because multiple t-test results are being shown on the plot 

.pull-left[
```{r popcor1, eval=F }
set.seed(1)
b <- c(0.8, 0.6, 0.4)
x <- w <- rnorm(1000)
for (t in 4:1000) {
for (j in 1:3) x[t] <- x[t] + b[j] * w[t - j]
}
 plot(x, type = "l")
```

```{r popcor2, eval=F}
acf(x)
```

```{r popcorout1, ref.label="popcor1", echo=F}
```



]

.pull-right[

```{r popcorout2, ref.label="popcor2", echo=F}
```

]

---

## Fitted MA models 

**Model fitted to simulated series**

An $MA(q)$ model can be fitted to data in `R` using the `arima` function with the `order` function parameter set to `c(0,0,q)` 

Unlike the function `ar`, the function `arima` does not  subtract the mean by default and estimates an intercept 

MA models cannot be expressed in a multiple regression form, the parameters are estimated with a numerical algorithm 

The function `arima` minimises the conditional sum of squares to estimate values of the parameters and will either return these if `method=c("CSS")` is specified or use them as initial values for MLE 

In the following code, a moving average model, x.ma, is fitted to the simulated series of the last section 

---

Looking at the parameter estimates, it can be seen that the 95% confidence interval

approximated by $coeff.\pm2$ s.e. of $coeff$) contain the underlying parameter values (0.8, 0.6 and 0.4) that were used in the simulations. 

Furthermore, the intercept is not significantly different from its underlying parameter value of zero 



```{r }
x.ma  <- arima(x, order=c(0,0,3))
x.ma 
```

---

Here is the `acf` 

```{r }
acf(x.ma$res[-1])
```
